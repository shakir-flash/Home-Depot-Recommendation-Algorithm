{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Home Depot - Use Case Study (Content recommender system)\n",
    "\n",
    "The following code is a use case task for Home Depot for recommendation of a content to users. \n",
    "\n",
    "The task for the case study is to build a model to recommend relevant content to the user based on the similarity between the search term and title of the content. The recommendations are one to many. The search designed is agnostic of the user's past behavior. So, the context for the recommendation is purely derived from the current search term issued by the user.\n",
    "\n",
    "This system will recommend relevant products or content from the dataset, leveraging natural language processing (NLP) techniques and embeddings to improve the relevance of the recommendations. My final objective is to evaluate the accuracy of the model using a labeled dataset and generate predictions for unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library initialization and Data Load:\n",
    "\n",
    "Libraries used in the case study are as follows:\n",
    "1. Pandas: For data manipulation and analysis.\n",
    "2. NumPy: Used for numerical operations & array handling.\n",
    "3. NLTK (Natural Language Toolkit): For text processing, lemmatization, and managing stopwords.\n",
    "4. re: Regular expressions for cleaning text.\n",
    "5. spaCy: For Named Entity Recognition (NER) and advanced NLP tasks.\n",
    "6. SentenceTransformer: To generate sentence embeddings using a pre-trained model.\n",
    "7. sklearn: For metrics such as cosine similarity, classification report, and accuracy score (Precision, Recall, F1 Score).\n",
    "\n",
    "We are working with three main datasets:\n",
    "\n",
    "`content_data`: Contains the product or content titles for which recommendations need to be generated. This dataset includes information such as the title and slug of each content piece.\n",
    "\n",
    "`label_data`: A labeled dataset with search terms and slugs, where each entry is tagged as either relevant or irrelevant for a particular search term.\n",
    "\n",
    "`test_data`: This dataset contains search terms for which we will generate recommendations without labels.\n",
    "We load these datasets into Pandas dataframes for manipulation and analysis.\n",
    "\n",
    "While loading the label_data, I found an issue at row 726. The headers of the file were misaligned, and the column names were incorrectly placed in the data row. To fix this:\n",
    "\n",
    "The actual header was set using the values of row 726.\n",
    "The erroneous row (row 726) was subsequently dropped from the dataset.\n",
    "This adjustment ensured the correct alignment of columns in label_data for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re, spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#data load\n",
    "content_data = pd.read_csv('data/content_data_MASTER.csv')\n",
    "label_data = pd.read_csv('data/labels_MASTER.csv', header=None)\n",
    "test_data = pd.read_csv('data/test_MASTER.csv')\n",
    "\n",
    "#removing duplicates based on 'title' as it may cause bias due to multiple entries (retrospective removal) \n",
    "content_data = content_data.drop_duplicates(subset='title', keep='first')\n",
    "\n",
    "#setting the header using the row at index 726 as the header is wrongly entered in that entry\n",
    "label_data.columns = label_data.iloc[726].values\n",
    "label_data = label_data.drop(index=726)\n",
    "\n",
    "#display the first few rows for exploration\n",
    "#print(content_data.head())\n",
    "#print(label_data.head())\n",
    "#print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start using the library and the associated functions, we need to first download the required functions. Quiet mode is set to TRUE to silence repeated downloads.\n",
    "\n",
    "Imported the following- Averaged perceptron tagger, Wordnet, Stopwords, Words, spaCy NER model, and spaCy stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading necessary NLTK resources (quiet mode for repeated downloads)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('words', quiet=True)\n",
    "\n",
    "#loading spaCy model for NER and stopword removal\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = nlp.Defaults.stop_words\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "combined_stopwords = spacy_stopwords.union(nltk_stopwords)\n",
    "\n",
    "#initializing lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis:\n",
    "\n",
    "The Exploratory Data Analysis (EDA) phase is essential for understanding the structure, content, and characteristics of the datasets. Here, I explored the data by gathering basic information, performing summary statistics, checking for data quality issues like duplicates (which i retrospectively removed in the above step), and identified frequently occurring values. This will help me prepare the data for further cleaning and modeling.\n",
    "\n",
    "1. Basic Information of the Datasets\n",
    "The info() function provides a summary of each dataset, including the number of entries, the data types, and the number of non-null values in each column.\n",
    "\n",
    "Content Data: We inspected the structure and integrity of the content data, ensuring that fields such as title and slug contain valid entries without missing values.\n",
    "Label Data: This dataset, which contains search terms and their corresponding labels, was checked for the number of entries and any missing or misaligned data.\n",
    "Test Data: The test data was analyzed to ensure that all search terms are present and complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic information\n",
    "print(\"Basic Information of the Content Data:\")\n",
    "print(content_data.info())\n",
    "\n",
    "print(\"\\nBasic Information of the Labels Data:\")\n",
    "print(label_data.info())\n",
    "\n",
    "print(\"\\nBasic Information of the Test Data:\")\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summary Statistics\n",
    "We used the describe() function to obtain summary statistics such as count, mean, and percentiles. This provides a general overview of numerical data in the datasets, allowing us to check for any irregularities, such as extremely large or small values.\n",
    "\n",
    "Content Data: The summary highlights statistics related to numerical columns in the dataset (if present), which could include fields like ratings or counts.\n",
    "Label Data: Summary statistics were used to understand the distribution of search terms and their labels.\n",
    "Test Data: We checked the basic distribution of search terms to ensure a balanced variety of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics\n",
    "print(\"\\nSummary of Content Data:\")\n",
    "print(content_data.describe())\n",
    "\n",
    "print(\"\\nSummary of Labels Data:\")\n",
    "print(label_data.describe())\n",
    "\n",
    "print(\"\\nSummary of Test Data:\")\n",
    "print(test_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Distribution of Labels\n",
    "The distribution of the Label column in the label data is important for understanding class balance. If one class (e.g., \"relevant\" or \"irrelevant\") dominates, it can lead to biased predictions. We used value_counts() to check the number of instances for each label.\n",
    "\n",
    "Observation: If the dataset is heavily imbalanced, we may need to adjust the modeling approach by using techniques such as oversampling or class weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of 'Label' column in the labels data\n",
    "print(\"\\nDistribution of the 'Label' column in Labels Data:\")\n",
    "print(label_data['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Duplicate Titles in Content Data\n",
    "Duplicates in content titles can cause bias in recommendations, as they may skew the results by giving some content undue prominence. Using duplicated(), we checked for repeated entries based on the title column in the content dataset and displayed the duplicated rows.\n",
    "\n",
    "Observation: Any duplicates found were removed in data load data steps to ensure that the model doesn't favor duplicate content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates in the content data\n",
    "print(\"\\nDuplicate Titles in Content Data:\")\n",
    "print(content_data[content_data.duplicated(subset='title', keep=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Frequent Search Terms in Labels Data\n",
    "To understand user behavior, we analyzed the most frequently occurring search terms in the label_data dataset using value_counts(). This helps in identifying popular search queries that the model will need to handle efficiently.\n",
    "\n",
    "Top 10 Frequent Search Terms: These insights into frequent search terms can inform future data cleaning and processing steps, especially if certain terms appear with high frequency and may require special handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequent search terms in the labels data\n",
    "print(\"\\nTop 10 Frequent Search Terms in Labels Data:\")\n",
    "print(label_data['searchTerm'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Frequent Content Titles in Content Data\n",
    "We also analyzed the top 10 most frequent content titles using value_counts(). Frequent titles could indicate the most popular products or pieces of content in the dataset.\n",
    "\n",
    "Top 10 Frequent Content Titles: Identifying repeated titles gives us an idea of common content themes and whether we need to adjust the model to handle any overrepresentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequent content titles in the content data\n",
    "print(\"\\nTop 10 Frequent Content Titles in Content Data:\")\n",
    "print(content_data['title'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels.to_csv('labels_check.csv', index=False)\n",
    "#content.to_csv('content_check.csv', index=False)\n",
    "#test.to_csv('test_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Pre-processing: \n",
    "This step is extremely crucial, since the model needs to receive quality data, and not noise. The cleaner the data, the better. This process is split into multiple steps.\n",
    "\n",
    "1. Step 1: Removal of the product specifications. \n",
    "\n",
    "The content data which is available does not have any individual numbers associated with it. All the recommendations and slugs do not contain numbers. So we can safely remove the numbers and the associated nuances.\n",
    "\n",
    "The `clean_product_specs` function removes irrelevant product specifications and unwanted characters from text. It:\n",
    "\n",
    "Removes words containing numbers, like model numbers (e.g., \"T123\"), which is not useful for understanding product descriptions, as it adds no value.\n",
    "\n",
    "Eliminates isolated 'x', commonly used in product dimensions (e.g., \"4x6\"), but irrelevant since we are removing the numbers.\n",
    "\n",
    "Removes extra spaces, ensuring clean and neatly formatted text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning product specifications and unwanted characters\n",
    "def clean_product_specs(text):\n",
    "    #removing words with product specifications which containing numbers\n",
    "    cleaned_text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)  #removes words that contain text/numbers\n",
    "    cleaned_text = re.sub(r'\\bx\\b', '', cleaned_text)  #removes isolated 'x'\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  #removes extra spaces\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of code performs text preprocessing for product data by:\n",
    "\n",
    "1. Loading an English dictionary to keep only meaningful English words.\n",
    "\n",
    "2. Defining custom stopwords that are identified as non-informative during data analysis (e.g., 'diy', 'guide').\n",
    "\n",
    "3. Preprocessing text by:\n",
    "\n",
    "    a) Cleaning product specifications.\n",
    "\n",
    "    b) Converting text to lowercase.\n",
    "\n",
    "    c) Removing standard and custom stopwords.\n",
    "\n",
    "    d) Performing part-of-speech-based lemmatization to reduce words to their base forms (nouns, verbs).\n",
    "\n",
    "    e) Retaining named entities (important terms like product names) and filtering out non-informative symbols.\n",
    "\n",
    "The result is a cleaned and structured text, ready for further analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english dictionary load to keep english words\n",
    "english_words = set(words.words())\n",
    "\n",
    "#defining custom stopwords identified through data scan\n",
    "combined_stopwords = set(stopwords.words('english')).union(\n",
    "    set(['diy', 'guide', 'tutorial', 'how-to', 'best', 'ideas', 'gal', 'in', 'ft'])\n",
    ")\n",
    "\n",
    "#preprocessing function with NER, punctuation removal and POS-based lemmatization\n",
    "def preprocess_text(text, custom_stopwords=None):\n",
    "    #calling function to clean product specifications\n",
    "    text = clean_product_specs(text)   \n",
    "    #lowercase conversion\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = []\n",
    "    entities = []\n",
    "    for token in doc:\n",
    "        #removing stopwords and custom stopwords\n",
    "        if token.text not in combined_stopwords and (custom_stopwords is None or token.text not in custom_stopwords):         \n",
    "            #skip tokens if they are non-informative symbols\n",
    "            if re.match(r'^\\W+$', token.text):\n",
    "                continue\n",
    "            #prioritizing named entity\n",
    "            if token.ent_type_:\n",
    "                entities.append(token.text)\n",
    "            else:\n",
    "                #POS-based lemmatization for non-entities\n",
    "                pos = token.pos_\n",
    "                if pos.startswith('N'):\n",
    "                    lemmatized_word = lemmatizer.lemmatize(token.text, pos='n')  #noun\n",
    "                elif pos.startswith('V'):\n",
    "                    lemmatized_word = lemmatizer.lemmatize(token.text, pos='v')  #verb\n",
    "                else:\n",
    "                    lemmatized_word = token.text  #others retained as is\n",
    "                #adding tokens to list\n",
    "                tokens.append(lemmatized_word)\n",
    "    #combine named entities and lemmatized tokens\n",
    "    processed_text = ' '.join(entities + tokens)\n",
    "    #remove extra spaces which may have come up\n",
    "    return re.sub(r'\\s+', ' ', processed_text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section applies the previously defined preprocessing function to clean and standardize the text data by doing the following:\n",
    "\n",
    "1. Preprocessing content titles: The preprocess_text function is applied to each title in the content_data dataset to clean product names and specifications.\n",
    "2. Preprocessing search terms in label data: The search terms in the label_data dataset undergo the same cleaning process to ensure consistency between the queries and content titles.\n",
    "3. Preprocessing search terms in test data: The search terms in the test_data dataset are also processed for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying preprocessing to content titles, search terms, and labels\n",
    "content_data['preprocessed_title'] = content_data['title'].apply(lambda x: preprocess_text(x))\n",
    "label_data['preprocessed_searchTerm'] = label_data['searchTerm'].apply(lambda x: preprocess_text(x))\n",
    "test_data['preprocessed_searchTerm'] = test_data['searchTerm'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#content_data.to_csv('content_check1.csv', index=False)\n",
    "#label_data.to_csv('labels_check1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building:\n",
    "\n",
    "I used the SentenceTransformer library (SBERT model) with the \"all-MiniLM-L6-v2\" model to generate embeddings for search terms and content titles. Sentence embeddings capture the semantic meaning of text, which is crucial for making recommendations based on content similarity.\n",
    "\n",
    "Metrics used for content matching:\n",
    "\n",
    "**Cosine Similarity:** This was employed to measure the similarity between the embeddings of search terms and content titles. The closer the cosine similarity score is to 1, the more relevant the content is for the search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#function to get SBERT embeddings\n",
    "def get_sbert_embeddings(texts):\n",
    "    return model.encode(texts)\n",
    "\n",
    "#call to get SBERT embeddings for all preprocessed content titles\n",
    "content_embeddings = get_sbert_embeddings(content_data['preprocessed_title'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendation Generation and Metrics Used**\n",
    "The recommendation system works by:\n",
    "\n",
    "Generating sentence embeddings for both the search terms and the content titles.\n",
    "\n",
    "Calculating the cosine similarity between a search term and all content titles.\n",
    "\n",
    "Filtering the content titles with a similarity score above a defined threshold (e.g., 0.35).\n",
    "\n",
    "Applying keyword boosting for domain-specific terms like \"power tool,\" \"garden,\" or \"hydrangea\" to enhance the relevance of certain content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of domain-specific keywords for boosting relevance\n",
    "boost_keywords = ['power tool', 'paint', 'home decor', 'drill', 'saw', 'garden', 'furniture', 'shower', 'christmas', 'hydrangea']\n",
    "\n",
    "#function to generate recommendations with cosine similarity, NER, and keyword boosting\n",
    "def generate_recommendations(search_term, content_embeddings, content_data, similarity_threshold=0.35, min_top_n=2, max_top_n=60):\n",
    "    search_embedding = model.encode([search_term])\n",
    "    cosine_similarities = cosine_similarity(search_embedding, content_embeddings).flatten()\n",
    "    \n",
    "    #applying keyword boosting for domain-related phrases\n",
    "    for keyword in boost_keywords:\n",
    "        if keyword in search_term:\n",
    "            cosine_similarities *= 1.1  #boost similarity by 10%\n",
    "    \n",
    "    valid_indices = np.where(cosine_similarities >= similarity_threshold)[0]\n",
    "    \n",
    "    if len(valid_indices) == 0:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no valid content\n",
    "    \n",
    "    top_n = max(min(len(valid_indices), max_top_n), min_top_n)\n",
    "    top_indices = valid_indices[np.argsort(cosine_similarities[valid_indices])[-top_n:][::-1]]\n",
    "    \n",
    "    recommendations = content_data.iloc[top_indices].copy()\n",
    "    recommendations['similarity_score'] = cosine_similarities[top_indices]\n",
    "    \n",
    "    return recommendations[['slug', 'title', 'similarity_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we iterate over the labeled data, extracting the preprocessed search terms and their corresponding slugs. For each search term, we generate recommendations using the cosine similarity between the search term embedding and content embeddings. We then check if the actual content slug is present in the recommended slugs to determine the predicted relevance.\n",
    "\n",
    "- **True Labels**: Whether the label in the dataset is marked as \"relevant.\"\n",
    "- **Predicted Labels**: Whether the actual slug is present in the recommended slugs.\n",
    "\n",
    "After predictions are generated for all search terms, we compute the model's performance using a classification report, which includes metrics such as precision, recall, and F1-score, alongside an overall accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model performance on label dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i, row in label_data.iterrows():\n",
    "    search_term = row['preprocessed_searchTerm']\n",
    "    slug = row['slug']\n",
    "    true_label = row['Label'].strip().lower() == 'relevant'\n",
    "    \n",
    "    recommendations = generate_recommendations(search_term, content_embeddings, content_data, similarity_threshold=0.35)\n",
    "    \n",
    "    if not recommendations.empty:\n",
    "        predicted_label = slug in recommendations['slug'].values\n",
    "    else:\n",
    "        predicted_label = False\n",
    "    \n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "# Display classification report and accuracy score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to make suggestions for our recommendation system on the `test.csv` file. Following is the code to call the generate_recommendations function and provide recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations for search terms in test data\n",
    "recommendations_dict = {}\n",
    "for search_term in test_data['preprocessed_searchTerm']:\n",
    "    recommendations_dict[search_term] = generate_recommendations(search_term, content_embeddings, content_data, similarity_threshold=0.5)\n",
    "\n",
    "# Display recommendations for each search term\n",
    "for search_term, recs in recommendations_dict.items():\n",
    "    print(f\"Search Term: {search_term}\")\n",
    "    print(recs)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************    ***END***    ******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate recommendations for search terms in test data\n",
    "# recommendations_dict = {}\n",
    "# for search_term in test_data['preprocessed_searchTerm']:\n",
    "#     recommendations_dict[search_term] = generate_recommendations(search_term, content_embeddings, content_data, similarity_threshold=0.5)\n",
    "\n",
    "# # Convert recommendations dictionary to a DataFrame for easier export\n",
    "# recommendations_df = pd.DataFrame([\n",
    "#     {'search_term': search_term, 'slug': rec['slug'], 'title': rec['title'], 'similarity_score': rec['similarity_score']}\n",
    "#     for search_term, recs in recommendations_dict.items()\n",
    "#     for _, rec in recs.iterrows()\n",
    "# ])\n",
    "\n",
    "# # Export recommendations to a CSV file\n",
    "# recommendations_df.to_csv('recommendations.csv', index=False)\n",
    "\n",
    "# print(\"Recommendations exported to 'recommendations.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Term: best wine glass\n",
      "                                                   slug  \\\n",
      "342        the-best-wine-glasses-to-complement-any-wine   \n",
      "1022                                   how-to-cut-glass   \n",
      "50    the-types-of-drinking-glasses-you-need-in-your...   \n",
      "1678                     how-to-pack-dishes-and-glasses   \n",
      "690         Types-of-cocktail-glasses-for-your-home-bar   \n",
      "343                           wine-coolers-buying-guide   \n",
      "955                        how-to-drill-a-hole-in-glass   \n",
      "1500                        how-to-replace-window-glass   \n",
      "512             types-of-beer-glasses-to-suit-every-sip   \n",
      "1551                  how-to-get-red-wine-out-of-carpet   \n",
      "273                  how-to-remove-scratches-from-glass   \n",
      "\n",
      "                                                  title  similarity_score  \n",
      "342        The Best Wine Glasses to Complement Any Wine          0.804738  \n",
      "1022                                   How to Cut Glass          0.661957  \n",
      "50    The Types of Drinking Glasses You Need in Your...          0.660341  \n",
      "1678                     How to Pack Dishes and Glasses          0.623062  \n",
      "690         Types of Cocktail Glasses for Your Home Bar          0.609600  \n",
      "343                          Wine Coolers Buying Guide           0.601573  \n",
      "955                        How to Drill a Hole in Glass          0.590166  \n",
      "1500                       How to Replace Window Glass           0.588821  \n",
      "512             Types of Beer Glasses to Suit Every Sip          0.562773  \n",
      "1551                  How to Get Red Wine Out of Carpet          0.539810  \n",
      "273                  How to Remove Scratches From Glass          0.538493  \n",
      "\n",
      "\n",
      "Search Term: primer paint\n",
      "                                                   slug  \\\n",
      "1261                                 how-to-spray-paint   \n",
      "598                 best-paint-sprayer-for-your-project   \n",
      "449                   best-spray-paint-for-your-project   \n",
      "994                          how-to-use-a-paint-sprayer   \n",
      "937                    how-to-prep-a-house-for-painting   \n",
      "68                              types-of-paint-finishes   \n",
      "2517                                bedroom-paint-ideas   \n",
      "480                                exterior-paint-ideas   \n",
      "2910         repainting-furniture-using-a-paint-sprayer   \n",
      "290                         how-to-choose-a-paint-color   \n",
      "1107                    how-to-prepare-a-room-for-paint   \n",
      "1807                                how-to-sponge-paint   \n",
      "1361                       how-to-make-canvas-paintings   \n",
      "1542                                how-to-prime-a-wall   \n",
      "1523                                how-to-paint-a-room   \n",
      "160                best-paint-stripper-for-your-project   \n",
      "1045                              how-to-paint-paneling   \n",
      "30                   best-paint-brushes-for-any-project   \n",
      "800                                   how-to-paint-trim   \n",
      "2043                    3-ways-to-repurpose-a-paint-can   \n",
      "1347                             how-to-paint-a-ceiling   \n",
      "1905                            faux-paint-finish-ideas   \n",
      "29                how-to-choose-the-best-concrete-paint   \n",
      "1692                             how-to-paint-furniture   \n",
      "2426                  ceiling-paint-ideas-for-your-home   \n",
      "319                    best-ceiling-paint-for-your-home   \n",
      "1013                                 how-to-paint-tiles   \n",
      "881                     how-to-get-paint-out-of-clothes   \n",
      "2632                         exterior-house-paint-ideas   \n",
      "654                 best-paint-roller-for-your-projects   \n",
      "46                   best-safety-equipment-for-painting   \n",
      "170            best-paint-for-your-next-cabinet-project   \n",
      "2447                           painting-tips-and-tricks   \n",
      "1194                           how-to-use-chalked-paint   \n",
      "2871  painting-the-exterior-of-our-house-with-the-pr...   \n",
      "658                   best-exterior-paint-for-your-home   \n",
      "2622  best-office-paint-colors-for-productivity-&-focus   \n",
      "2966                        how-to-paint-an-accent-wall   \n",
      "303                 types-of-concrete-paint-applicators   \n",
      "27                 types-of-boat-paint-and-marine-paint   \n",
      "986                          how-to-clean-painted-walls   \n",
      "967                      how-to-get-paint-out-of-carpet   \n",
      "265                                best-interior-paints   \n",
      "\n",
      "                                                  title  similarity_score  \n",
      "1261                                 How to Spray Paint          0.733186  \n",
      "598         Best Paint Sprayers for Any Type of Project          0.708561  \n",
      "449                   Best Spray Paint for Your Project          0.698802  \n",
      "994                          How to Use a Paint Sprayer          0.674697  \n",
      "937                    How to Prep a House for Painting          0.660859  \n",
      "68                             Types of Paint Finishes           0.627879  \n",
      "2517                                Bedroom Paint Ideas          0.626457  \n",
      "480                                Exterior Paint Ideas          0.620441  \n",
      "2910         Repainting Furniture Using a Paint Sprayer          0.607530  \n",
      "290                         How To Choose a Paint Color          0.603543  \n",
      "1107                    How to Prepare a Room for Paint          0.596230  \n",
      "1807                                How to Sponge Paint          0.596195  \n",
      "1361                      How to Make Canvas Paintings           0.593743  \n",
      "1542                                How to Prime a Wall          0.592731  \n",
      "1523                                How to Paint a Room          0.592168  \n",
      "160                Best Paint Stripper For Your Project          0.591359  \n",
      "1045                              How to Paint Paneling          0.589162  \n",
      "30                   Best Paint Brushes for Any Project          0.587759  \n",
      "800                                   How to Paint Trim          0.580730  \n",
      "2043                   3 Ways to Repurpose a Paint Can           0.576355  \n",
      "1347                             How to Paint a Ceiling          0.574926  \n",
      "1905                            Faux Paint Finish Ideas          0.574759  \n",
      "29                How to Choose the Best Concrete Paint          0.571934  \n",
      "1692                             How to Paint Furniture          0.569475  \n",
      "2426                  Ceiling Paint Ideas for Your Home          0.567921  \n",
      "319                    Best Ceiling Paint for Your Home          0.567921  \n",
      "1013                                 How to Paint Tiles          0.564851  \n",
      "881                     How to Get Paint Out of Clothes          0.562899  \n",
      "2632                         Exterior House Paint Ideas          0.552845  \n",
      "654                Best Paint Rollers For Your Projects          0.550467  \n",
      "46                   Best Safety Equipment for Painting          0.542231  \n",
      "170            Best Paint for Your Next Cabinet Project          0.536345  \n",
      "2447                           Painting Tips and Tricks          0.533175  \n",
      "1194                           How to Use Chalked Paint          0.526498  \n",
      "2871  Painting the Exterior of our House With the Pr...          0.526433  \n",
      "658                   Best Exterior Paint for Your Home          0.523540  \n",
      "2622  Best Office Paint Colors for Productivity & Focus          0.519329  \n",
      "2966                        How to Paint an Accent Wall          0.511798  \n",
      "303                 Types of Concrete Paint Applicators          0.507784  \n",
      "27                 Types of Boat Paint and Marine Paint          0.505484  \n",
      "986                          How to Clean Painted Walls          0.504253  \n",
      "967                      How to Get Paint Out of Carpet          0.502554  \n",
      "265                 Best Interior Paints for Every Room          0.500042  \n",
      "\n",
      "\n",
      "Search Term: tools for work\n",
      "                                          slug  \\\n",
      "162     best-electrical-tools-for-your-project   \n",
      "8                                 rotary-tools   \n",
      "132   must-have-automotive-tools-for-mechanics   \n",
      "226              best-jigsaws-for-your-project   \n",
      "431                          types-of-wrenches   \n",
      "121                  what-is-a-woodworking-jig   \n",
      "86                          how-to-use-a-drill   \n",
      "2268              how-to-maintain-garden-tools   \n",
      "396                   how-to-use-a-rotary-tool   \n",
      "848                        how-to-use-a-jigsaw   \n",
      "\n",
      "                                         title  similarity_score  \n",
      "162     Best Electrical Tools for Your Project          0.584345  \n",
      "8                                 Rotary Tools          0.578669  \n",
      "132   Must Have Automotive Tools for Mechanics          0.563485  \n",
      "226              Best Jigsaws for Your Project          0.535132  \n",
      "431                          Types of Wrenches          0.529903  \n",
      "121                  What Is a Woodworking Jig          0.517462  \n",
      "86                          How to Use a Drill          0.516934  \n",
      "2268              How to Maintain Garden Tools          0.513600  \n",
      "396                   How to Use a Rotary Tool          0.510924  \n",
      "848                        How to Use a Jigsaw          0.502453  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Manually setting multiple search terms\n",
    "# search_terms = [\"best wine glass\", \"primer paint\", \"tools for work\"]\n",
    "\n",
    "# # Loop through each search term\n",
    "# for search_term in search_terms:\n",
    "#     # Preprocess the search term before recommendation\n",
    "#     preprocessed_search_term = preprocess_text(search_term)\n",
    "\n",
    "#     # Generate recommendations using the current search term\n",
    "#     recommendations = generate_recommendations(preprocessed_search_term, content_embeddings, content_data, similarity_threshold=0.5)\n",
    "\n",
    "#     # Display recommendations for the current search term\n",
    "#     print(f\"Search Term: {search_term}\")\n",
    "#     print(recommendations)\n",
    "#     print(\"\\n\")  # Add a line break between different search terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
